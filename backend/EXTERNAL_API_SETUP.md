# ğŸš€ External API Setup Guide

## âœ… **What We've Fixed:**

1. **No more local ML models** - No memory crashes on Render
2. **External API transcription** - Uses your Colab-hosted WhisperX
3. **Deployable on Render** - Lightweight, no heavy dependencies
4. **Same functionality** - Transcription, translation, subtitle overlay

## ğŸ”‘ **Setup Steps:**

### **1. Keep Your Colab Running:**
- Your Colab notebook with ngrok must stay active
- The URL `https://fbec50a7a6c4.ngrok-free.app` must be accessible
- **Important**: ngrok URLs change when you restart Colab

### **2. Update Your Colab API:**
You need to add a `/transcribe` endpoint to your Colab FastAPI app:

```python
from fastapi import FastAPI, UploadFile, File
import whisperx
import torch
import tempfile
import os

app = FastAPI(title="WhisperX Inference API")

# Load WhisperX model (small/medium/large)
device = "cuda" if torch.cuda.is_available() else "cpu"
model = whisperx.load_model("small", device=device)

@app.post("/transcribe")
async def transcribe_audio(file: UploadFile = File(...)):
    """Transcribe uploaded audio file"""
    try:
        # Save uploaded file temporarily
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as tmp_file:
            content = await file.read()
            tmp_file.write(content)
            tmp_file_path = tmp_file.name
        
        # Transcribe with WhisperX
        audio = whisperx.load_audio(tmp_file_path)
        result = model.transcribe(audio)
        
        # Clean up temp file
        os.unlink(tmp_file_path)
        
        return result
        
    except Exception as e:
        return {"error": str(e)}

# Your existing ngrok setup...
```

### **3. Set Environment Variables:**
```bash
# In your .env file or Render dashboard:
GOOGLE_API_KEY=your_google_api_key_here
```

### **4. Install Dependencies:**
```bash
pip install -r requirements-deploy.txt
```

## ğŸ¯ **How It Works Now:**

### **Before (Local Models):**
- âŒ Load WhisperX (~145MB) at startup
- âŒ Load alignment model (~1.27GB) at startup  
- âŒ Load speaker diarization (~1.27GB) at startup
- âŒ **Result: Crashes on Render (out of memory)**

### **After (External API):**
- âœ… **No models loaded** at startup
- âœ… **API calls** to your Colab when needed
- âœ… **Lightweight** - only FastAPI + basic packages
- âœ… **Result: Deploys successfully on Render**

## ğŸš€ **Deploy to Render:**

1. **Push your changes:**
```bash
git add .
git commit -m "Use external Colab-hosted WhisperX API"
git push origin main
```

2. **In Render dashboard:**
   - Set `GOOGLE_API_KEY` environment variable
   - Deploy!

## ğŸ§ª **Test Locally First:**
```bash
cd backend
python -c "from Extractor.script_generator import process_video_pipeline; print('âœ… Imports work!')"
```

## âš ï¸ **Important Notes:**

1. **Colab must stay running** during your demo
2. **ngrok URLs change** - update `WHISPERX_API_URL` if needed
3. **No speaker diarization** - basic transcription only
4. **Internet dependent** - requires Colab to be accessible

## ğŸ‰ **Benefits:**

- **âœ… Deployable on Render** (no memory issues)
- **âœ… Same functionality** (transcription, translation, overlay)
- **âœ… Free hosting** (Colab + ngrok)
- **âœ… Professional quality** (WhisperX models)
- **âœ… No maintenance** (hosted on Colab)

Your pipeline now works exactly the same but can actually be deployed on Render! ğŸš€
